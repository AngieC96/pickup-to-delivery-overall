{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24ad314bf282ec83",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Pickup to Delivery Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb71195be0f3a22f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from haversine import haversine, Unit\n",
    "from sklearn.metrics.pairwise import haversine_distances, manhattan_distances\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "sys.path.insert(0, os.path.expanduser('./'))\n",
    "import query_runner as qr\n",
    "import utils\n",
    "from estimator import BaselineModel_sum, BaselineModel_mean, LinearModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eb5fbdb862edbe",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_query_path = './queries/'\n",
    "dwh_config, livedb_config, parameters_config = utils.load_config(config_file='./config.ini')\n",
    "datalake_connection = qr.create_connection(db='datalake')\n",
    "#monolith_connection = qr.create_connection(user=livedb_config['monolith_username'], password=livedb_config['monolith_password'], db='livedb')\n",
    "#dispatching_db_connection = qr.create_connection(user=livedb_config['dispatching_db_username'], password=livedb_config['dispatching_db_password'], db='dispatchingdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26eb0ba80de7f8e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_date = parameters_config['start_date']\n",
    "end_date = parameters_config['end_date']\n",
    "country_code = parameters_config['country_code']\n",
    "cities = parameters_config['cities']\n",
    "\n",
    "print(f'Start date: {start_date} | End date: {end_date} | Countries: {country_code} | Cities: {cities}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c251ccf4f2beb1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'start_date': start_date,\n",
    "    'end_date': end_date,\n",
    "    'country_code': country_code,\n",
    "    'cities': cities\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0d6dbf6375ce8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de21fec65a3d1b1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query_name = '''\n",
    "SELECT\n",
    "    olf.country_code                                 AS country_code,\n",
    "    olf.city_code                                    AS city_code,\n",
    "    olf.order_id                                     AS order_id,\n",
    "    olf.courier_id                                   AS courier_id,\n",
    "    olf.order_created_local_datetime                 AS creation_timestamp,\n",
    "    olf.order_activated_local_datetime               AS activation_timestamp,\n",
    "    olf.courier_transport                            AS transport,\n",
    "    olf.order_picked_up_local_datetime               AS pickup_timestamp,\n",
    "    olf.order_arrival_to_delivery_local_datetime     AS delivery_entering_timestamp,\n",
    "    olf.order_delivered_local_datetime               AS delivery_timestamp,\n",
    "    olf.order_pickup_latitude                        AS pickup_latitude,\n",
    "    olf.order_pickup_longitude                       AS pickup_longitude,\n",
    "    olf.order_delivery_latitude                      AS delivery_latitude,\n",
    "    olf.order_delivery_longitude                     AS delivery_longitude,\n",
    "    olf.order_time_zone                              AS time_zone,\n",
    "    olf.p_creation_date\n",
    "FROM delta.courier_routing_courier_ml_features_odp.order_level_features AS olf\n",
    "WHERE order_final_status = 'DeliveredStatus'\n",
    "    AND order_number_of_assignments = 1\n",
    "    AND order_bundle_index IS NULL\n",
    "    AND p_creation_date >= DATE '[start_date]' AND p_creation_date < DATE '[end_date]'\n",
    "    AND country_code IN ('[country_code]')\n",
    "    AND city_code IN ([cities])\n",
    "'''\n",
    "\n",
    "query = qr.Query(base_query_path, query_name, datalake_connection, parameters_dict=parameters, query_from_file = False)\n",
    "\n",
    "df = query.run()\n",
    "df = df.fillna(value=np.nan)\n",
    "\n",
    "data = df.copy()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb60e56ce9b31a2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3269019e5c025a9d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad7421cf883f255",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df8f7cd6a104940",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc64e33e9ec8a4a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the number of null rows\n",
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a2d084be3ddfe8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove rows with null values: we have many rows, so we can afford to remove them\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea941235b67758e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83402ad003b2989e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be4b81e03b7586",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Compute new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80163d0a54873861",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert the creation time to datetime\n",
    "data['creation_timestamp'] = pd.to_datetime(data['creation_timestamp'])\n",
    "data['activation_timestamp'] = pd.to_datetime(data['activation_timestamp'])\n",
    "data['pickup_timestamp'] = pd.to_datetime(data['pickup_timestamp'])\n",
    "data['delivery_timestamp'] = pd.to_datetime(data['delivery_timestamp'])\n",
    "data['delivery_entering_timestamp'] = pd.to_datetime(data['delivery_entering_timestamp'])\n",
    "\n",
    "# Compute the delivery date and the delivery time\n",
    "data['creation_date'] = data['creation_timestamp'].dt.date\n",
    "data['creation_time'] = data['creation_timestamp'].dt.time\n",
    "data['creation_hour'] = data['creation_timestamp'].dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6ea1be09344c80",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To determine whether a coordinate is in degrees or radians, you can consider the typical ranges and values for latitude and longitude:\n",
    "1. **Degrees:**\n",
    "   - Latitude ranges from -90 to 90 degrees.\n",
    "   - Longitude ranges from -180 to 180 degrees.\n",
    "   - Values are typically whole numbers or decimals within these ranges.\n",
    "2. **Radians:**\n",
    "   - Latitude and longitude in radians will range from approximately -π/2 to π/2 for latitude and -π to π for longitude.\n",
    "   - Values are typically small decimals (e.g., 0.5, 1.0, etc.).\n",
    "\n",
    "Given our dataset, as the values in the columns `pickup_latitude`, `pickup_longitude`, `delivery_latitude`, `delivery_longitude` fall within the typical range for degrees, it is safe to assume that these coordinates are in degrees.\n",
    "\n",
    "There is a difference in how the `haversine` library, the `sklearn`'s `haversine_distances`, and the `sklearn`'s `manhattan_distances` function compute and return the distances. Let's break down the differences and how to resolve them:\n",
    "1. **Haversine Library:**\n",
    "   - The `haversine` library directly computes the distance between two points and returns a single scalar value.\n",
    "2. **Sklearn's `haversine_distances`:**\n",
    "   - The `haversine_distances` function from `sklearn` returns a distance matrix. When you input two points, it returns a 1x1 matrix (a nested list) containing the distance. This is why you would see the result in squared parentheses like `[[]]`. We extract the single value using `[0][0]`.\n",
    "   - To use these coordinates with sklearn's `haversine_distances` function, you need to convert them to radians using `np.radians`.\n",
    "   - Additionally, the `haversine_distances` function returns the distance in radians, not in meters. To convert this to meters, you need to multiply by the Earth's radius (approximately 6371000 meters).\n",
    "3. **Sklearn's `manhattan_distances`:**\n",
    "   - The `manhattan_distances` function computes the Manhattan distance between two points and returns a distance matrix. We extract the single value from the 1x1 matrix using `[0][0]`.\n",
    "   - Additionally, the `manhattan_distances` function from sklearn computes the distance based on the Cartesian coordinates provided. Since latitude and longitude are angular measurements, the result will not be in meters but in degrees. To convert the Manhattan distance from degrees to meters, you need to account for the Earth's curvature. \n",
    "      - The conversion factor for latitude is approximately 111,320 meters per degree.\n",
    "      - The conversion factor for longitude varies based on the latitude. At the equator, it's approximately 111,320 meters per degree, but it decreases as you move towards the poles.\n",
    "      - Convert the latitude and longitude differences to meters.\n",
    "      - Sum the absolute differences to get the Manhattan distance in meters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808ab1bc4476de8a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert degrees to radians\n",
    "data['pickup_latitude_rad'] = np.radians(data['pickup_latitude'])\n",
    "data['pickup_longitude_rad'] = np.radians(data['pickup_longitude'])\n",
    "data['delivery_latitude_rad'] = np.radians(data['delivery_latitude'])\n",
    "data['delivery_longitude_rad'] = np.radians(data['delivery_longitude'])\n",
    "\n",
    "# Earth's radius in meters\n",
    "earth_radius_m = 6371.0088 * 1000  # average earth radius - https://en.wikipedia.org/wiki/Earth_radius#Mean_radius\n",
    "\n",
    "# Conversion factors\n",
    "meters_per_degree_lat = 111320  # Approximate meters per degree of latitude\n",
    "\n",
    "def manhattan_distance_in_meters(row):\n",
    "    # Convert latitude and longitude differences to meters\n",
    "    lat_diff_m = abs(row['pickup_latitude'] - row['delivery_latitude']) * meters_per_degree_lat\n",
    "    # Convert longitude difference to meters, considering the latitude\n",
    "    lon_diff_m = abs(row['pickup_longitude'] - row['delivery_longitude']) * meters_per_degree_lat * np.cos(np.radians((row['pickup_latitude'] + row['delivery_latitude']) / 2))\n",
    "    # Sum the absolute differences to get the Manhattan distance in meters\n",
    "    return lat_diff_m + lon_diff_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93468fe8bc656f1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['pd_distance_haversine_m'] = data.apply(\n",
    "    lambda x: haversine(\n",
    "        (x['pickup_latitude'], x['pickup_longitude']),\n",
    "        (x['delivery_latitude'], x['delivery_longitude']),\n",
    "        unit=Unit.METERS\n",
    "    ), axis=1\n",
    ")\n",
    "data['pd_distance_haversine_m_sk'] = data.apply(\n",
    "    lambda x: haversine_distances(\n",
    "        np.array([[x['pickup_latitude_rad'], x['pickup_longitude_rad']]]),\n",
    "        np.array([[x['delivery_latitude_rad'], x['delivery_longitude_rad']]])\n",
    "    )[0][0] * earth_radius_m, axis=1\n",
    ")\n",
    "data['pd_distance_manhattan_m'] = data.apply(manhattan_distance_in_meters, axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6be2faf50c7f774",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the number of null rows\n",
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da7791843042776",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Save the dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "400dcfe4569bd3da",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "data.to_pickle(\"data/dataframe.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da57697f71fdf68",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "It's better to use the parquet format, as it is more efficient and faster to read and write. Besides, it is a columnar format, which is more suitable for analytical queries. We can also partition the data by creation date and city, which will help to speed up the queries and allows to analyze different timeframes and different cities if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3198338e55332c9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parquet appends the data in the files, it doesn't overwrite them, so we need to manually remove the folder with its content to avoid duplicated data\n",
    "shutil.rmtree(\"data/parquet/\")\n",
    "os.makedirs(\"data/parquet/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a357e3ed80c39b1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.to_parquet(\"data/parquet/dataframe.parquet\", index=False, partition_cols=['creation_date', 'city_code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f700ca8f9a310ca",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f459d6342f561915",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "data = pd.read_pickle(\"data/dataframe.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecce593d1c02912",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_parquet(\"data/parquet/dataframe.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71786bb2d8f08ad7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Histogram of the # of data per day / hour\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.hist(data['creation_timestamp'], bins = 1000)\n",
    "plt.title('Histogram of the # of data per day / hour')\n",
    "plt.xlabel('Day / Hour')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b49b7bdfaf6dc14",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.hist(data['creation_date'], bins = 14)\n",
    "plt.title('Histogram of the # of data per day')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b3fb2c7e172f38",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.hist(data['creation_hour'])\n",
    "plt.title('Histogram of the # of data per hour')\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d0cbff51d0870",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check the distribution of the transport types\n",
    "data['transport'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fa4556b397ea7b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check the distribution of the distances\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.hist(data['pd_distance_haversine_m'], bins = 1000)\n",
    "plt.xlim(0, 10000)\n",
    "plt.title('Histogram of the distances')\n",
    "plt.xlabel('Distance (m)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f24b33b07b58e9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843f73749bdce7ee",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_set_perc = 0.1\n",
    "days_for_test = 7\n",
    "k_cv = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aed5934e3c1f8f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Database split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2574aa199337f236",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = data\n",
    "y = data['delivery_entering_timestamp'] - data['pickup_timestamp']\n",
    "y = pd.Series(y, name='pickup_to_delivery')\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1bd6034ee61016",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As we are dealing with a time-series dataset (orders are placed at different times), we will split the data based on the creation timestamp, leaving out the last 10% of the data for testing. This will help to understand the performance of the model on unseen data, as in reality we will have to test the model on data created on day+1 with respect to our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cf1844840c2240",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.sort_values('creation_timestamp', inplace=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_set_perc, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0cc9098900ec66",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578fea794feb9a3d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1aab43ff9f5211",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc44e42fd992ca8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In case we want to test different hyperparameters, we will use cross-validation\n",
    "#scores = cross_val_score(<estimator>, X, y, cv=k_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7282f116c476aa5c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Database split using directly the creation date\n",
    "\n",
    "As we have partitioned the data by city and creation date, we can use this information to split the data. This will help to avoid data leakage, as we will not have data from the future in the training set.\n",
    "This is much better than just sorting the data by the creation timestamp and taking 10% of the dataset as test set, as we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c872336bd56642",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We take the last week of the dataset to test the model\n",
    "begin_test_date = pd.to_datetime(end_date) - pd.Timedelta(days=days_for_test-1)\n",
    "begin_test_date = begin_test_date.strftime(\"%Y-%m-%d\")\n",
    "print(f'Start date: {start_date} | Begin test date: {begin_test_date} | End date: {end_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac70f793bb888aa",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_parquet(\"data/parquet/dataframe.parquet/\", filters=[('creation_date', '<', begin_test_date)])\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74662b30246725ca",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check that there are no nulls deriving from a wrong writing of parquet files (appending instead of overwriting)\n",
    "X_train.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7062f2936f260656",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = X_train['delivery_entering_timestamp'] - X_train['pickup_timestamp']\n",
    "y_train = pd.Series(y_train, name='pickup_to_delivery')\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7c005256b289b6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1830d6e04cb2eed0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = pd.read_parquet(\"data/parquet/dataframe.parquet\", filters=[('creation_date', '>=', begin_test_date)])\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273b4efbb39767db",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "To compute the MAE, we need to do a power to 2, but if I use the type `np.timedelta64(1, \"ns\")` for `y_test` I get the following error:\n",
    "`TypeError: cannot perform __pow__ with this index type: TimedeltaArray`\n",
    "Therefore we will use the type `np.float64` for `y_test`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2bc643e6376ab1bb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ce014a35efad12",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test = (X_test['delivery_entering_timestamp'] - X_test['pickup_timestamp']).dt.total_seconds()\n",
    "y_test = pd.Series(y_test, dtype=np.float64, name='pickup_to_delivery')\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb62def0b2bf287",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2fff1089f25047",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01843bd221d9df1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Baseline Models\n",
    "\n",
    "### BaselineModel_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7319e4fbfc086581",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_bl_sum = BaselineModel_sum()\n",
    "model_bl_sum.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ce61d074b1f290",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_expanded = X_test.copy()\n",
    "X_test_expanded['y_test_predicted'] = model_bl_sum.predict(X_test)\n",
    "X_test_expanded['y_test'] = (X_test_expanded['delivery_entering_timestamp'] - X_test_expanded['pickup_timestamp']).dt.total_seconds()\n",
    "X_test_expanded['diff'] = X_test_expanded['y_test_predicted'] - X_test_expanded['y_test']\n",
    "X_test_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7ceb8d51efef42",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_bl_sum.predict(X_test.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d31a26bb43bab07",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### BaselineModel_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199e5c6e339d7c1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_bl_mean = BaselineModel_mean()\n",
    "model_bl_mean.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2363ec8ae10e56",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_expanded2 = X_test.copy()\n",
    "X_test_expanded2['y_test_predicted'] = model_bl_mean.predict(X_test)\n",
    "X_test_expanded2['y_test'] = (X_test_expanded2['delivery_entering_timestamp'] - X_test_expanded2['pickup_timestamp']).dt.total_seconds()\n",
    "X_test_expanded2['diff'] = X_test_expanded2['y_test_predicted'] - X_test_expanded2['y_test']\n",
    "X_test_expanded2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7329630cd310504",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_bl_mean.predict(X_test.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65c835da4563a72",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Evaluation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92356bab8168e738",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_bl_sum.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_test.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "313c80aa93b215c9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06a05c54e737f56",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_bl_mean.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917c211d4ba0e732",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fd6a83d81004d2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_linear = LinearModel()\n",
    "model_linear.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e466c1357db9ecc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_expanded3 = X_test.copy()\n",
    "X_test_expanded3['y_test_predicted'] = model_linear.predict(X_test)\n",
    "X_test_expanded3['y_test'] = (X_test_expanded3['delivery_entering_timestamp'] - X_test_expanded3['pickup_timestamp']).dt.total_seconds()\n",
    "X_test_expanded3['diff'] = X_test_expanded['y_test_predicted'] - X_test_expanded3['y_test']\n",
    "X_test_expanded3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd65b11375e85284",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_linear.predict(X_test.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9facbc14adebf3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_linear.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
